{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import warnings\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def myFunc(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "# COMPILE\n",
    "tb = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 229 images belonging to 2 classes.\n",
      "Found 95 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\datta\\Desktop\\tfidf\\lowfps\\train',  # this is the target directory\n",
    "        target_size=(64,64),  # all images will be resized to 300x300\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\datta\\Desktop\\tfidf\\lowfps\\validation',\n",
    "        target_size=(64,64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\datta\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.4102 - accuracy: 0.7837 - val_loss: 0.0583 - val_accuracy: 0.9792\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.1371 - accuracy: 0.9633 - val_loss: 0.0729 - val_accuracy: 0.9787\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 0.0709 - accuracy: 0.9714 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.1373 - accuracy: 0.9421 - val_loss: 0.6737 - val_accuracy: 0.9787\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 9s 294ms/step - loss: 0.0728 - accuracy: 0.9879 - val_loss: 0.0136 - val_accuracy: 0.9792\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 0.0566 - accuracy: 0.9752 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0319 - accuracy: 0.9878 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.0166 - accuracy: 0.9918 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 9s 292ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0305 - accuracy: 0.9879 - val_loss: 2.0284e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.3768e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 9s 291ms/step - loss: 9.5092e-04 - accuracy: 1.0000 - val_loss: 3.6675e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 6.2282e-04 - accuracy: 1.0000 - val_loss: 2.4757e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 5.2967e-04 - accuracy: 1.0000 - val_loss: 4.3852e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 6.1460e-04 - accuracy: 1.0000 - val_loss: 4.7195e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 2.3305e-04 - accuracy: 1.0000 - val_loss: 9.7938e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 5.4889e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 2.3713e-04 - accuracy: 1.0000 - val_loss: 1.0249e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 1.2718e-04 - accuracy: 1.0000 - val_loss: 8.8092e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22a3e301448>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=250 // batch_size  ,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#model.save_weights('50_epochs.hdf5')  # always save your weights after training or during training\n",
    "model_json = model.to_json()\n",
    "with open(\"20_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"20_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
